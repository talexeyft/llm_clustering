# LLM Provider API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# LLM Configuration
DEFAULT_LLM_PROVIDER=openrouter
DEFAULT_MODEL=qwen/qwen-3-next
DEFAULT_TEMPERATURE=0.0
DEFAULT_MAX_TOKENS=4096
PREFER_DUAL_GPU=true
ALLOW_LOCAL_LLM_FALLBACK=true

# OpenRouter Configuration
OPENROUTER_MODEL=qwen/qwen-3-next

# Ollama Configuration (local)
OLLAMA_API_URL=http://localhost:11434/api
OLLAMA_MODEL=qwen3:30b

# Triton Configuration (local)
TRITON_API_URL=http://localhost:8000
TRITON_MODEL=qwen2_5_0_5b

# Clustering Configuration
CLUSTERING_BATCH_SIZE=60
MAX_CLUSTERS_PER_BATCH=8
MIN_REQUESTS_PER_CLUSTER=3
RARE_CASE_BUFFER_SIZE=20
CLUSTERING_SIMILARITY_THRESHOLD=0.8

# Storage
BATCHES_DIR=ai_data/batches
RESULTS_DIR=ai_data/results

# Logging
LOG_LEVEL=INFO
LOG_FILE=ai_data/clustering.log
LOG_PROMPTS=true
LOG_PROMPT_DIR=ai_data/prompts
LOG_PROMPT_PAYLOADS=false
METRICS_FILE=ai_data/metrics.csv
