# LLM Clustering

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–∞–∫—Ç-—Ü–µ–Ω—Ç—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM-–º–æ–¥–µ–ª–µ–π.

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üöÄ **–í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π API** –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
- üîå **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö LLM-–º–æ–¥–µ–ª–µ–π** —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- üìä **–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- üîÑ **–î–æ—Ä–∞–∑–º–µ—Ç–∫–∞** —Å —É—á–µ—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
- üíæ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞** –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
- üéØ **–ë–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç** –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
- üì¶ **–õ–µ–≥–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞** –≤ –ª—é–±–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- ‚ö° **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è inference
- üè≠ **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤**: Ollama, OpenRouter, OpenAI, Anthropic, Triton

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ö–∞–∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ editable mode (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
pip install -e /path/to/llm_clustering

# –ò–ª–∏ –æ–±—ã—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
pip install /path/to/llm_clustering

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
python -c "import llm_clustering; print(llm_clustering.__version__)"
llm-clustering --help
```

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```bash
# –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python3 -m venv venv
source venv/bin/activate

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt
# –∏–ª–∏ —Å dev-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
pip install -e ".[dev]"
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–°–∫–æ–ø–∏—Ä—É–π—Ç–µ `env.example` –≤ `.env` –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

```bash
cp env.example .env
```

**–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é**: –ü—Ä–æ–µ–∫—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **Ollama** —Å –º–æ–¥–µ–ª—å—é **`qwen3:30b`**.

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å Ollama
ollama serve

# –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å
ollama pull qwen3:30b

# –í .env —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ:
DEFAULT_LLM_PROVIDER=ollama
OLLAMA_MODEL=qwen3:30b
OLLAMA_API_URL=http://localhost:11434/api
```

### –î—Ä—É–≥–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- **ollama** - –ª–æ–∫–∞–ª—å–Ω–∞—è Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- **openrouter** - OpenRouter API
- **openai** - OpenAI API
- **anthropic** - Anthropic API
- **triton** - Triton Inference Server

–ü–æ–¥—Ä–æ–±–Ω–µ–µ —Å–º. –≤ —Ä–∞–∑–¥–µ–ª–µ [–ö–∞—Å—Ç–æ–º–Ω—ã–µ LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã](#–∫–∞—Å—Ç–æ–º–Ω—ã–µ-llm-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã).

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from llm_clustering import ClusteringPipeline
import pandas as pd

# –°–æ–∑–¥–∞—Ç—å pipeline
pipeline = ClusteringPipeline()

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
df = pd.DataFrame({
    "text": ["–ù–µ –º–æ–≥—É –≤–æ–π—Ç–∏", "–ó–∞–±—ã–ª –ø–∞—Ä–æ–ª—å", "–¢–æ–≤–∞—Ä –Ω–µ –ø—Ä–∏—à–µ–ª"]
})

# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞—Ç—å
result = pipeline.fit(df, text_column="text")

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
print(f"Coverage: {result.coverage:.1f}%")
print(f"Clusters: {len(result.clusters)}")

for cluster in result.clusters:
    print(f"  - {cluster.name}: {cluster.count} requests")
```

### –° –∫–∞—Å—Ç–æ–º–Ω–æ–π LLM

```python
from llm_clustering import ClusteringPipeline, BaseLLMProvider

class MyLLM(BaseLLMProvider):
    def chat_completion(self, messages, temperature=None, max_tokens=None):
        # –í–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
        return json_response
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –º–æ–∂–Ω–æ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å
    def embed(self, texts): raise NotImplementedError()
    def cluster(self, texts, num_clusters=None): raise NotImplementedError()
    def describe_cluster(self, texts): raise NotImplementedError()

pipeline = ClusteringPipeline(llm_provider=MyLLM())
result = pipeline.fit(df, text_column="text")
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CLI

```bash
# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–∞
llm-clustering --input data.csv --text-column text --limit 100

# –°–ø—Ä–∞–≤–∫–∞
llm-clustering --help
```

### –î–µ–º–æ-–¥–∞–Ω–Ω—ã–µ

–í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –≤–∫–ª—é—á–µ–Ω —Ñ–∞–π–ª `ai_data/demo_sample.csv.zip` —Å 1000 –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏:

```bash
# –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å
unzip ai_data/demo_sample.csv.zip -d ai_data/

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ 20 —Å—ç–º–ø–ª–∞—Ö
llm-clustering --input ai_data/demo_sample.csv --limit 20
```

## üîå –ö–∞—Å—Ç–æ–º–Ω—ã–µ LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

```python
from llm_clustering import ClusteringPipeline, Settings

# –ß–µ—Ä–µ–∑ Settings
settings = Settings(
    default_llm_provider="ollama",
    ollama_model="qwen3:30b",
    default_temperature=0.0,
)
pipeline = ClusteringPipeline(settings=settings)

# –ò–ª–∏ —á–µ—Ä–µ–∑ .env
# DEFAULT_LLM_PROVIDER=ollama
# OLLAMA_MODEL=qwen3:30b
```

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç —Ç–æ–ª—å–∫–æ –º–µ—Ç–æ–¥ `chat_completion`:

```python
from llm_clustering import BaseLLMProvider
import requests

class MyCustomProvider(BaseLLMProvider):
    def __init__(self):
        self.api_url = "https://my-llm-api.com/v1/chat"
        self.api_key = "your-api-key"
        self.temperature = 0.0
        self.max_tokens = 4096
    
    def chat_completion(self, messages, temperature=None, max_tokens=None):
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.
        
        Args:
            messages: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π [{"role": "user", "content": "text"}]
            temperature: —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_tokens: –º–∞–∫—Å. –∫–æ–ª-–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            str: JSON-—Å—Ç—Ä–æ–∫–∞ —Å –æ—Ç–≤–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        """
        response = requests.post(
            self.api_url,
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={
                "messages": messages,
                "temperature": temperature or self.temperature,
                "max_tokens": max_tokens or self.max_tokens,
            }
        )
        return response.json()["choices"][0]["message"]["content"]
    
    # –≠—Ç–∏ –º–µ—Ç–æ–¥—ã –º–æ–∂–Ω–æ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å
    def embed(self, texts): raise NotImplementedError()
    def cluster(self, texts, num_clusters=None): raise NotImplementedError()
    def describe_cluster(self, texts): raise NotImplementedError()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
pipeline = ClusteringPipeline(llm_provider=MyCustomProvider())
result = pipeline.fit(df, text_column="text")
```

### –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ —Ñ–∞–±—Ä–∏–∫–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–î–ª—è —É–¥–æ–±–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ `get_llm_provider()`:

1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `src/llm_clustering/llm/my_provider.py`
2. –î–æ–±–∞–≤—å—Ç–µ –≤ `src/llm_clustering/llm/factory.py`:

```python
from llm_clustering.llm.my_provider import MyProvider

class LLMFactory:
    _providers = {
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ ...
        "myprovider": MyProvider,
    }
```

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ—Ä–µ–∑ —Ñ–∞–±—Ä–∏–∫—É:

```python
from llm_clustering.llm.factory import get_llm_provider

provider = get_llm_provider("myprovider")
pipeline = ClusteringPipeline(llm_provider=provider)
```

–ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ: [doc/adding_custom_provider.md](doc/adding_custom_provider.md)

## üéØ –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

–ë–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:

```python
business_context = """
–†–∞–∑–º–µ—Ç–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –±–æ—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏.
–†–∞–∑–¥–µ–ª—è–π –ø—Ä–æ–±–ª–µ–º—ã –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:
- –ü—Ä–æ—Å—Ç—ã–µ: FAQ (–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ–º—ã–µ)
- –°—Ä–µ–¥–Ω–∏–µ: —Ç—Ä–µ–±—É—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- –°–ª–æ–∂–Ω—ã–µ: –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏
"""

pipeline = ClusteringPipeline(business_context=business_context)
result = pipeline.fit(df, text_column="text")
```

### –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤

–ü—Ä–æ–º–ø—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ `src/llm_clustering/clustering/`:
- `judge.py` - –ø—Ä–æ–º–ø—Ç –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã
- `proposer.py` - –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

–í—ã –º–æ–∂–µ—Ç–µ:
1. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç—ã –Ω–∞–ø—Ä—è–º—É—é –≤ –∫–æ–¥–µ
2. –ü–µ—Ä–µ–¥–∞—Ç—å `business_context` –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ pipeline
3. –°–æ–∑–¥–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã `Judge` –∏ `Proposer` —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏

```python
from llm_clustering.clustering import Judge, Proposer

class MyJudge(Judge):
    def build_prompt(self, ...):
        # –í–∞—à –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        return custom_prompt

pipeline = ClusteringPipeline()
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π API
```

## üìö API –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –ø–æ —á–∞—Å—Ç—è–º:

```python
for partial in pipeline.fit_partial(df, batch_size=50):
    print(f"Batch {partial.batch_number}: {partial.processed_rows}/{partial.total_rows}")
    print(f"New clusters: {len(partial.new_clusters)}")
    
    # –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç
    if partial.processed_rows >= 200:
        break
```

### 2. –î–æ—Ä–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–î–æ—Ä–∞–∑–º–µ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:

```python
# –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞
result1 = pipeline.fit(df_part1, text_column="text")

# –î–æ—Ä–∞–∑–º–µ—Ç–∫–∞ —Å —É—á–µ—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
result2 = pipeline.refit(
    df_part2,
    previous_assignments=result1.assignments,
    text_column="text"
)
```

### 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

```python
from pathlib import Path

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
pipeline.save_clusters(Path("clusters.json"))

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤ –Ω–æ–≤—ã–π pipeline
new_pipeline = ClusteringPipeline()
new_pipeline.load_clusters(Path("clusters.json"))

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
result = new_pipeline.fit(new_df, text_column="text")
```

### 4. –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

```python
# –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —á–∞—Å—Ç–æ—Ç–µ)
clusters = pipeline.get_clusters()

for cluster in clusters:
    print(f"{cluster.name}: {cluster.count} requests")
    print(f"  Summary: {cluster.summary}")
    print(f"  Criteria: {cluster.criteria}")
```

### 5. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

```python
# –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 100 —Å—Ç—Ä–æ–∫
result = pipeline.fit(df, text_column="text", limit=100)

# –ù–∞—á–∞—Ç—å —Å 100-–π —Å—Ç—Ä–æ–∫–∏
for partial in pipeline.fit_partial(df, batch_size=50, start_from=100):
    pass
```

### 6. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
settings = Settings(
    parallel_inference_batch_size=10,  # 10 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
)
pipeline = ClusteringPipeline(settings=settings)
```

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### ClusteringResult

```python
result = pipeline.fit(df)

# –ê—Ç—Ä–∏–±—É—Ç—ã
result.batch_id              # ID –±–∞—Ç—á–∞
result.assignments           # DataFrame —Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è–º–∏
result.clusters              # –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
result.coverage              # –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∫—Ä—ã—Ç–∏—è (0-100)
result.metrics               # –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
result.total_requests        # –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤
result.assigned_requests     # –ù–∞–∑–Ω–∞—á–µ–Ω–æ –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã
```

### PartialResult

```python
for partial in pipeline.fit_partial(df, batch_size=50):
    partial.batch_number        # –ù–æ–º–µ—Ä –±–∞—Ç—á–∞
    partial.batch_id            # ID –±–∞—Ç—á–∞
    partial.assignments         # DataFrame —Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    partial.new_clusters        # –ù–æ–≤—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ —ç—Ç–æ–º –±–∞—Ç—á–µ
    partial.processed_rows      # –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫
    partial.total_rows          # –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫
```

### ClusterRecord

```python
clusters = pipeline.get_clusters()

for cluster in clusters:
    cluster.cluster_id          # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
    cluster.name                # –ù–∞–∑–≤–∞–Ω–∏–µ
    cluster.summary             # –û–ø–∏—Å–∞–Ω–∏–µ
    cluster.criteria            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–Ω–µ—Å–µ–Ω–∏—è
    cluster.sample_requests     # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ (ID)
    cluster.count               # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
    cluster.status              # –°—Ç–∞—Ç—É—Å (active/tentative)
    cluster.created_at          # –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
    cluster.updated_at          # –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
llm_clustering/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ llm_clustering/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py         # –ü—É–±–ª–∏—á–Ω—ã–π API
‚îÇ       ‚îú‚îÄ‚îÄ api.py              # ClusteringPipeline
‚îÇ       ‚îú‚îÄ‚îÄ config/             # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
‚îÇ       ‚îú‚îÄ‚îÄ llm/                # LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ base.py         # BaseLLMProvider
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ factory.py      # LLMFactory
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ollama_provider.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ openrouter_provider.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ       ‚îú‚îÄ‚îÄ clustering/         # –õ–æ–≥–∏–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ clusterer.py    # –û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ judge.py        # –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ proposer.py     # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ registry.py     # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ       ‚îú‚îÄ‚îÄ pipeline/           # Pipeline runner
‚îÇ       ‚îú‚îÄ‚îÄ data/               # –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
‚îÇ       ‚îî‚îÄ‚îÄ utils/              # –£—Ç–∏–ª–∏—Ç—ã
‚îú‚îÄ‚îÄ tests/                      # –Æ–Ω–∏—Ç-—Ç–µ—Å—Ç—ã
‚îú‚îÄ‚îÄ ai_experiments/             # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ —Ç–µ—Å—Ç—ã
‚îú‚îÄ‚îÄ ai_doc/                     # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ ai_data/                    # –î–∞–Ω–Ω—ã–µ, –ª–æ–≥–∏, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ batches/                # –ë–∞—Ç—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ results/                # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                # –õ–æ–≥–∏ –ø—Ä–æ–º–ø—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ reports/                # –û—Ç—á–µ—Ç—ã QA
‚îú‚îÄ‚îÄ doc/                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ examples.py                 # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
‚îî‚îÄ‚îÄ README.md                   # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üìñ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∞–Ω–Ω—ã–º

–í—Ö–æ–¥–Ω–æ–π DataFrame –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å:

- **–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü**: —Ç–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `text`)
- **–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã**: –ª—é–±—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:**
- –ï—Å–ª–∏ `request_id` –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
- –§–æ—Ä–º–∞—Ç –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: `req-{batch_id}-{index}`
- –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Å–≤–æ–∏ `request_id` –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –≤–∞—à—É —Å–∏—Å—Ç–µ–º—É

## üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ Jupyter Notebook

```python
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ kernel
!pip install -e /path/to/llm_clustering

from llm_clustering import ClusteringPipeline
import pandas as pd
import matplotlib.pyplot as plt

pipeline = ClusteringPipeline()
result = pipeline.fit(df, text_column="text")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
cluster_counts = [c.count for c in result.clusters]
cluster_names = [c.name[:30] for c in result.clusters]

plt.barh(cluster_names, cluster_counts)
plt.xlabel("Number of requests")
plt.title("Cluster Distribution")
plt.tight_layout()
plt.show()
```

### –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏

```python
from llm_clustering import ClusteringPipeline, Settings
from pathlib import Path

# –ö–∞—Å—Ç–æ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
settings = Settings(
    clustering_batch_size=30,
    max_clusters_per_batch=5,
    default_temperature=0.1,
    default_llm_provider="ollama",
    ollama_model="qwen3:30b",
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
pipeline = ClusteringPipeline(
    settings=settings,
    business_context="–†–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è –±–æ—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏",
    registry_path=Path("ai_data/my_clusters.json")
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞
result = pipeline.fit(df, text_column="text", limit=100)

# –†–∞–±–æ—Ç–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
for cluster in result.clusters:
    print(f"{cluster.name}: {cluster.count} requests")
    print(f"  Summary: {cluster.summary}")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
result.assignments.to_csv("results.csv", index=False)
pipeline.save_clusters(Path("final_clusters.json"))
```

–ë–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ [examples.py](examples.py).

## üîß Troubleshooting

### ModuleNotFoundError

```bash
pip install -e /path/to/llm_clustering
```

### LLM –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ LLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω (–¥–ª—è Ollama: `ollama serve`)
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (`ollama list`)

### –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON

- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `temperature=0.0`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç—ã –≤ `src/llm_clustering/clustering/`

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **[–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ API](ai_doc/library_usage.md)** - –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
- **[–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](ai_doc/quickstart.md)** - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –ø–µ—Ä–≤—ã–µ —à–∞–≥–∏
- **[–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞](doc/adding_custom_provider.md)** - —Å–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
- **[–ü—Ä–∏–º–µ—Ä—ã](examples.py)** - –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
- **[–î–µ–º–æ-–¥–∞–Ω–Ω—ã–µ](ai_doc/demo_data.md)** - –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ó–∞–ø—É—Å–∫ unit-—Ç–µ—Å—Ç–æ–≤
PYTHONPATH=src:$PYTHONPATH pytest

# –¢–µ—Å—Ç –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–≥–æ API
PYTHONPATH=src:$PYTHONPATH python ai_experiments/test_library_api.py

# –¢–µ—Å—Ç Ollama
PYTHONPATH=src:$PYTHONPATH python ai_experiments/test_ollama_success.py

# –¢–µ—Å—Ç OpenRouter
PYTHONPATH=src:$PYTHONPATH python ai_experiments/test_openrouter_simple.py
```

## üöÄ –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ CLI

```bash
# MVP –ø–∞–π–ø–ª–∞–π–Ω
INPUT=ai_data/demo_sample.csv make run

# –° –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º
llm-clustering --input ai_data/demo_sample.csv --limit 100

# –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
llm-clustering \
  --input data.csv \
  --text-column message \
  --batch-id batch-001 \
  --limit 200
```

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
- –ë–∞—Ç—á–∏ –≤ `ai_data/batches/`
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ `ai_data/results/`
- –õ–æ–≥–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ `ai_data/prompts/`
- –û—Ç—á–µ—Ç—ã QA –≤ `ai_data/reports/`

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT

## üë• –ê–≤—Ç–æ—Ä—ã

Alex - alex@example.com

## ü§ù –í–∫–ª–∞–¥

–í–∫–ª–∞–¥ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ—Ç—Å—è! –°–æ–∑–¥–∞–≤–∞–π—Ç–µ issue –∏–ª–∏ pull request.

